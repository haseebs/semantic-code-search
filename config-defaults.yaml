model_type:
  desc:
  value: transformer_model
code_encoder_type:
  desc:
  value: "self_attention_encoder"
query_encoder_type:
  desc:
  value: "self_attention_encoder"
encoder_sharing_mode:
  desc:
  value: "all"
code_max_num_tokens:
  desc:
  value: 200
query_max_num_tokens:
  desc:
  value: 30
learning_rate:
  desc:
  value: 0.001
batch_size:
  desc:
  value: 256
loss:
  desc:
  value: "cosine"
vocab_size:
  desc:
  value: 10000
embedding_dim:
  desc:
  value: 128
dropout_prob:
  desc:
  value: 0.1
gradient_clip:
  desc:
  value: 1
margin:
  desc:
  value: 1
max_epochs:
  desc:
  value: 300
patience:
  desc:
  value: 5
use_bpe:
  desc:
  value: True
vocab_pct_bpe:
  desc:
  value: 0.5
vocab_count_threshold:
  desc:
  value: 10
keep_keys:
  desc:
  value: ["language", "docstring_tokens", "code_tokens"]
keep_keys_test:
  desc:
  value: ["language", "docstring_tokens", "code_tokens", "docstring", "code"]
data_dirs:
  desc:
  value: ["../CodeSearchNet_official/resources/data/ruby/final/jsonl"]
self_attention_nheads:
  desc:
  value: 8
self_attention_nhid:
  desc:
  value: 512
self_attention_nlayers:
  desc:
  value: 3
